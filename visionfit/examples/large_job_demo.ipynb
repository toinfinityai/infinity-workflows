{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8487fc2f",
   "metadata": {},
   "source": [
    "# Submitting a large batch of jobs\n",
    "\n",
    "Often, you're going to want a big dataset that will take a while to render -- and you probably don't want to keep a notebook kernel going overnight. This notebook writes the submitted job IDs to disk, which allows you to close the notebook and re-open it at a later time to query the jobs' statuses. You can then choose to download data as individual jobs complete, or wait until the entire batch has completed. \n",
    "\n",
    "Specifically, this notebook shows how to:\n",
    "  1. Define a distribution of parameters for the batch submission.\n",
    "  2. Submit many jobs in batch mode.\n",
    "  3. Query job status in non-blocking mode.\n",
    "  4. Visualize dataset statistics + filter for specific properties.\n",
    "\n",
    "----- \n",
    "\n",
    "__Note__: The demonstration here was downsampled for easier viewing in the notebook, so the outputs in the cells will reflect small batch jobs. You can generate batch jobs with many more videos that have higher resolution, better frame rates, and more reps.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e14cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "import infinity_tools.visionfit.api as api\n",
    "from infinity_tools.visionfit.vis import visualize_job_params\n",
    "from infinity_tools.visionfit.vis import summarize_batch_results_as_dataframe, visualize_batch_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e217b",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d832add",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = \"TOKEN\"\n",
    "SERVER = \"https://api.toinfinity.ai/\"\n",
    "GENERATOR = \"visionfit-v0.4.0\"\n",
    "OUT_DIR = \"tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "sesh = api.VisionFitSession(token=TOKEN, generator=GENERATOR, server=SERVER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d6d7c",
   "metadata": {},
   "source": [
    "### Check API Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd67452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your usage stats for the last N days (30 in the example below).\n",
    "usage_data_last_30_days = sesh.get_usage_stats_last_n_days(n_days=30)\n",
    "print(\"Usage in the last 30 days\")\n",
    "pprint(usage_data_last_30_days)\n",
    "\n",
    "# Use datetime and a lower-level API for a more precise/custom range of usage stats.\n",
    "from datetime import datetime\n",
    "from infinity_core.api import get_usage_datetime_range\n",
    "start_time = datetime.fromisoformat(\"2022-07-15\")\n",
    "end_time = datetime.fromisoformat(\"2022-08-20\")\n",
    "usage_data_late_summer_2022 = get_usage_datetime_range(token=TOKEN, server=SERVER, start_time=start_time, end_time=end_time)\n",
    "print(\"\\nUsage in late summer 2022\")\n",
    "pprint(usage_data_late_summer_2022.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299f3b8",
   "metadata": {},
   "source": [
    "### Define distribution of parameters for the batch submission \n",
    "\n",
    "In this example, we will show how to create a large dataset of arm raise recordings with the following constraints:\n",
    "  - All videos will contain a single type of exercise (`exercise`, ARM_RAISE-DUMBBELL) \n",
    "  - All videos have 4 total reps (`num_reps`, 4)\n",
    "  - The resulting distribution of gender will be evenly split (`gender`, 50% male and 50% female)\n",
    "  - Each scene will be well-lit but not over-saturated (`lighting_power`, ~300 units)\n",
    "  - The camera will be placed between floor and table height (`camera_height`, ~1.2 meters)\n",
    "  - The resulting videos will have a low frame rate (`frame_rate`, 6 fps)\n",
    "  - The resulting videos will have a resolution of 256x256 pixels (`image_height` and `image_width`, 256 pixels x 256 pixels)\n",
    "  \n",
    "**Users can update the specification of `job_params` to fit their exact dataset needs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b8e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_jobs = 1000\n",
    "batch_name = \"uppercut left large job demo\" # change to a description of your dataset.\n",
    "\n",
    "# Set some initial parameters.\n",
    "job_params = [\n",
    "        sesh.sample_input(\n",
    "            exercise = \"UPPERCUT-LEFT\",\n",
    "            num_reps = 4,\n",
    "            lighting_power = float(random.gauss(300.0, 20.0)),\n",
    "            camera_height = float(random.gauss(1.2, 0.2)),\n",
    "            frame_rate=6,\n",
    "            image_height=256,\n",
    "            image_width=256\n",
    "        ) for _ in range(num_jobs)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c1a71",
   "metadata": {},
   "source": [
    "Before submitting our full video jobs to the API, we can visualize the distributions of our parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeab9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_job_params(job_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2bd08f",
   "metadata": {},
   "source": [
    "### Submit many jobs in batch mode.\n",
    "\n",
    "After verifying our parameters are in the correct range, we can submit a large batch of jobs to the API.\n",
    "\n",
    "High-resolution videos can take some time to render (~20 minutes per video), so this part is **non-blocking**. That is, you can run this cell and then shut down your notebook if you like. The job ids are saved to your local disk, so you can pick right up in the next section when you come back.\n",
    "\n",
    "**Note**: We don't actually want to submit a job for 1000 videos for this demo notebook, so the next cell will just take the first 5. **Delete the next cell when you're ready to generate videos at scale.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e759af",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_params = job_params[:5] #comment out or delete this cell for the full jobs array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09773c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = sesh.submit(\n",
    "    job_params=job_params,\n",
    "    is_preview=False,\n",
    "    batch_name=batch_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641ce62",
   "metadata": {},
   "source": [
    "### Reconstituting a batch later on\n",
    "\n",
    "You can reconstitute a submitted batch locally from the Infinity cloud API. Examples of when you would want to do this: (a) you come back to check on a large batch in a fresh notebook instance at a later date, (b) your notebook instance crashes or you exited it out, or (c) you want to revisit a batch from a long time ago.\n",
    "\n",
    "You can always view your batches by logging in to the [Infinity User Portal](https://api.toinfinity.ai/admin/api/batch/). This will give you information about previously submitted batches and their individual jobs.\n",
    "\n",
    "To locally reconstitute a batch, just grab the `batch_id` from the batch you are interested in from the User Portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we will get the `batch_id` from the `batch` instance in local memory. But you can easily get the\n",
    "# `batch_id` from the Infinity User Portal.\n",
    "batch_id = batch.batch_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217a3b4",
   "metadata": {},
   "source": [
    "### Query job status in non-blocking mode.\n",
    "\n",
    "We next show how to check on the status of a specific batch (potentially after closing and restarting this notebook). You only need to provide a path to the associated folder. Note that you can choose to move onto the next cell and download data before all jobs have successfully completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f03b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstitute our batch process state (replace `batch_id` with the ID for your desired batch).\n",
    "batch = sesh.batch_from_api(batch_id=batch_id)\n",
    "\n",
    "# Poll the server to see the status of our batch job.\n",
    "print(f\"{batch.num_jobs - batch.get_num_jobs_remaining()}/{batch.num_jobs} submitted jobs have completed\")\n",
    "\n",
    "completed_jobs = batch.get_completed_jobs()\n",
    "valid_jobs = batch.get_valid_completed_jobs()\n",
    "\n",
    "num_submitted = batch.num_jobs\n",
    "num_completed = len(completed_jobs)\n",
    "num_in_progress = num_submitted - num_completed\n",
    "num_successful = len(valid_jobs)\n",
    "num_failed = num_completed - num_successful\n",
    "\n",
    "print(f\"{num_successful}/{num_completed} completed jobs have a valid URL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466b76cf",
   "metadata": {},
   "source": [
    "#### Download completed jobs\n",
    "\n",
    "Using the cell from above, we can download the completed jobs. We will only download the completed jobs that have a valid URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e855d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_path = OUT_DIR + batch_name\n",
    "_download_ok = batch.download(path=batch_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7beaecb",
   "metadata": {},
   "source": [
    "### Visualize dataset statistics + filter for specific properties\n",
    "\n",
    "Finally, we compile some of the metadata and all of the job parameters that were submitted into a dataframe. This allows us to see the distribution of the resulting dataset. In addition, we can query the dataset for specific properties, which allows us to curate a desired training set for a given ML application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a2db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "df = summarize_batch_results_as_dataframe(batch_path)\n",
    "df.round(2).query('avg_percent_occlusion < 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_batch_results(batch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aeac98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
